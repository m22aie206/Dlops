{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PRBZzUxaAHPe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IjBQvQ4YJLSz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpUgPSI7ATMN",
        "outputId": "69f4c4fa-43da-4f26-d782-0f9d2911bee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2 to ./usps.bz2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6579383/6579383 [00:01<00:00, 4092109.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2 to ./usps.t.bz2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1831726/1831726 [00:01<00:00, 1476951.31it/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "#Load datsets\n",
        "train_loader = torch.utils.data.DataLoader(datasets.USPS(root=\".\", train=True, download=True, transform=transform), batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(datasets.USPS(root=\".\", train=False, download=True, transform=transform), batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NZu4yqWoBhhW"
      },
      "outputs": [],
      "source": [
        "# MLP Architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(16*16, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 16*16)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JZZuLLseHL5U"
      },
      "outputs": [],
      "source": [
        "# CNN Architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # Add changes in Assignment 2 - Changes in kernel\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cAz40gE3HSRB"
      },
      "outputs": [],
      "source": [
        "#Initialization\n",
        "mlp_model1 = MLP()\n",
        "cnn_model2 = CNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DwYNgzrOHcjf"
      },
      "outputs": [],
      "source": [
        "#Optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "# Add changes in Assignment 2 - Chaning in the learning rate\n",
        "mlp_optimizer = optim.Adam(mlp_model1.parameters(), lr=0.0012)\n",
        "# Add changes in Assignment 2 - Chaning in the learning rate\n",
        "cnn_optimizer = optim.Adam(cnn_model2.parameters(), lr=0.0012)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REMFGQu6HpnR",
        "outputId": "e896c32e-2f9a-4a66-aeec-3f5113a51d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multilayer Perceptron: Epoch [1/10], Loss: 0.5431\n",
            "Multilayer Perceptron: Epoch [2/10], Loss: 0.1747\n",
            "Multilayer Perceptron: Epoch [3/10], Loss: 0.1233\n",
            "Multilayer Perceptron: Epoch [4/10], Loss: 0.0896\n",
            "Multilayer Perceptron: Epoch [5/10], Loss: 0.0741\n",
            "Multilayer Perceptron: Epoch [6/10], Loss: 0.0590\n",
            "Multilayer Perceptron: Epoch [7/10], Loss: 0.0422\n",
            "Multilayer Perceptron: Epoch [8/10], Loss: 0.0369\n",
            "Multilayer Perceptron: Epoch [9/10], Loss: 0.0268\n",
            "Multilayer Perceptron: Epoch [10/10], Loss: 0.0200\n"
          ]
        }
      ],
      "source": [
        "#MLP Model Training \n",
        "mlp_model1.train()\n",
        "for epoch in range(10):\n",
        "    r_loss = 0.0\n",
        "    for i in train_loader:\n",
        "        inputs, labels = i\n",
        "        mlp_optimizer.zero_grad()\n",
        "        outputs = mlp_model1(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        mlp_optimizer.step()\n",
        "        r_loss += loss.item()\n",
        "    print(f'Multilayer Perceptron: Epoch [{epoch+1}/10], Loss: {r_loss/len(train_loader):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zpDW4s0IHtv",
        "outputId": "6bae56bb-4892-4ff4-830d-30ef2909cc27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Convolution Neural Network: epoch [1/10], Loss: 0.4611\n",
            "Convolution Neural Network: epoch [2/10], Loss: 0.1057\n",
            "Convolution Neural Network: epoch [3/10], Loss: 0.0744\n",
            "Convolution Neural Network: epoch [4/10], Loss: 0.0439\n",
            "Convolution Neural Network: epoch [5/10], Loss: 0.0403\n",
            "Convolution Neural Network: epoch [6/10], Loss: 0.0241\n",
            "Convolution Neural Network: epoch [7/10], Loss: 0.0267\n",
            "Convolution Neural Network: epoch [8/10], Loss: 0.0179\n",
            "Convolution Neural Network: epoch [9/10], Loss: 0.0127\n",
            "Convolution Neural Network: epoch [10/10], Loss: 0.0187\n"
          ]
        }
      ],
      "source": [
        "#Conbvolution Neural Network Model Training\n",
        "cnn_model2.train()\n",
        "for epoch in range(10):\n",
        "    r1_loss = 0.0\n",
        "    for j in train_loader:\n",
        "        inputs, labels = j\n",
        "        cnn_optimizer.zero_grad()\n",
        "        outputs = cnn_model2(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        cnn_optimizer.step()\n",
        "        r1_loss += loss.item()\n",
        "    print(f'Convolution Neural Network: epoch [{epoch+1}/10], Loss: {r1_loss/len(train_loader):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayYfIE-Il6i",
        "outputId": "a8d6a069-948e-493e-e674-258ce6f41981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multilayer perceptron Accuracy on test data set: 93.82%\n",
            "CNN Accuracy on test data set: 96.11%\n"
          ]
        }
      ],
      "source": [
        "#Evaluation for MLP and CNN\n",
        "mlp_model1.eval()\n",
        "c_mlp = 0\n",
        "t_mlp = 0\n",
        "with torch.no_grad():\n",
        "    for k in test_loader:\n",
        "        inputs, labels = k\n",
        "        outputs = mlp_model1(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        t_mlp += labels.size(0)\n",
        "        c_mlp += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Multilayer perceptron Accuracy on test data set: {100 * c_mlp / t_mlp:.2f}%')\n",
        "\n",
        "#CNN model\n",
        "cnn_model2.eval()\n",
        "c1_cnn = 0\n",
        "t1_cnn = 0\n",
        "with torch.no_grad():\n",
        "    for l in test_loader:\n",
        "        inputs, labels = l\n",
        "        outputs = cnn_model2(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        t1_cnn += labels.size(0)\n",
        "        c1_cnn += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'CNN Accuracy on test data set: {100 * c1_cnn / t1_cnn:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MP6Jr0JIJPnt"
      },
      "outputs": [],
      "source": [
        "# MOdel Evaluation\n",
        "def evaluate_model(model, data_loader):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='weighted')\n",
        "    recall = recall_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "    return accuracy, precision, recall, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggdySdYLJYab",
        "outputId": "972d71cc-a6d0-453b-e51d-7f0399259161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multilayer perceptron Model:\n",
            "Accuracy: 0.9382\n",
            "Precision: 0.9393\n",
            "Recall: 0.9382\n",
            "Confusion Matrix:\n",
            "[[346   0   2   0   3   0   6   0   1   1]\n",
            " [  0 254   1   3   0   0   5   0   1   0]\n",
            " [  1   0 181   2   1   3   1   1   7   1]\n",
            " [  0   0   3 142   0  13   0   1   6   1]\n",
            " [  1   2   3   1 183   1   3   1   1   4]\n",
            " [  2   0   0   3   1 149   1   0   2   2]\n",
            " [  0   0   3   0   2   1 164   0   0   0]\n",
            " [  0   0   1   0   6   0   0 135   3   2]\n",
            " [  1   0   2   4   0   1   0   1 155   2]\n",
            " [  0   0   0   1   1   0   0   0   1 174]]\n",
            "\n",
            "Convolution Neural Network Model:\n",
            "Accuracy: 0.9611\n",
            "Precision: 0.9623\n",
            "Recall: 0.9611\n",
            "Confusion Matrix:\n",
            "[[351   0   1   2   2   0   2   0   0   1]\n",
            " [  0 258   0   0   5   0   0   1   0   0]\n",
            " [  1   0 179   5   3   1   0   1   8   0]\n",
            " [  1   0   0 157   0   7   0   0   1   0]\n",
            " [  0   2   0   0 193   1   0   1   0   3]\n",
            " [  1   0   0   4   0 152   0   0   1   2]\n",
            " [  0   1   0   0   4   0 165   0   0   0]\n",
            " [  0   0   0   1   7   0   0 139   0   0]\n",
            " [  0   0   0   0   1   3   0   0 160   2]\n",
            " [  0   0   0   0   0   0   0   0   2 175]]\n"
          ]
        }
      ],
      "source": [
        "mlp_accuracy, mlp_precision, mlp_recall, mlp_cm = evaluate_model(mlp_model1, test_loader)\n",
        "\n",
        "cnn_accuracy, cnn_precision, cnn_recall, cnn_cm = evaluate_model(cnn_model2, test_loader)\n",
        "\n",
        "#Evaluation Metrices\n",
        "print(\"Multilayer perceptron Model:\")\n",
        "print(f\"Accuracy: {mlp_accuracy:.4f}\")\n",
        "print(f\"Precision: {mlp_precision:.4f}\")\n",
        "print(f\"Recall: {mlp_recall:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(mlp_cm)\n",
        "print()\n",
        "print(\"Convolution Neural Network Model:\")\n",
        "print(f\"Accuracy: {cnn_accuracy:.4f}\")\n",
        "print(f\"Precision: {cnn_precision:.4f}\")\n",
        "print(f\"Recall: {cnn_recall:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cnn_cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FcDYoevKMKk"
      },
      "source": [
        "## Tenspor Board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IC2gGfozJzIC"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "A3SrALiXJ11s"
      },
      "outputs": [],
      "source": [
        "mlp_writer = SummaryWriter('logs/mlp')\n",
        "cnn_writer = SummaryWriter('logs/cnn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7_DBMGIjJ4iC"
      },
      "outputs": [],
      "source": [
        "def evaluate_tensorboard_model(model, data_loader, writer, epoch):\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average='weighted')\n",
        "    recall = recall_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    # Log metrics\n",
        "    writer.add_scalar('Accuracy', accuracy, epoch)\n",
        "    writer.add_scalar('Precision', precision, epoch)\n",
        "    writer.add_scalar('Recall', recall, epoch)\n",
        "    writer.add_pr_curve('Precision-Recall Curve', torch.tensor(true_labels), torch.tensor(predictions), epoch)\n",
        "\n",
        "    return accuracy, precision, recall, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8GYLNiSKC8h",
        "outputId": "80f83b42-82ef-4461-aca7-bde74eb6d4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Model:\n",
            "Accuracy: 0.9382\n",
            "Precision: 0.9393\n",
            "Recall: 0.9382\n",
            "Confusion Matrix:\n",
            "[[346   0   2   0   3   0   6   0   1   1]\n",
            " [  0 254   1   3   0   0   5   0   1   0]\n",
            " [  1   0 181   2   1   3   1   1   7   1]\n",
            " [  0   0   3 142   0  13   0   1   6   1]\n",
            " [  1   2   3   1 183   1   3   1   1   4]\n",
            " [  2   0   0   3   1 149   1   0   2   2]\n",
            " [  0   0   3   0   2   1 164   0   0   0]\n",
            " [  0   0   1   0   6   0   0 135   3   2]\n",
            " [  1   0   2   4   0   1   0   1 155   2]\n",
            " [  0   0   0   1   1   0   0   0   1 174]]\n",
            "\n",
            "CNN Model:\n",
            "Accuracy: 0.9611\n",
            "Precision: 0.9623\n",
            "Recall: 0.9611\n",
            "Confusion Matrix:\n",
            "[[351   0   1   2   2   0   2   0   0   1]\n",
            " [  0 258   0   0   5   0   0   1   0   0]\n",
            " [  1   0 179   5   3   1   0   1   8   0]\n",
            " [  1   0   0 157   0   7   0   0   1   0]\n",
            " [  0   2   0   0 193   1   0   1   0   3]\n",
            " [  1   0   0   4   0 152   0   0   1   2]\n",
            " [  0   1   0   0   4   0 165   0   0   0]\n",
            " [  0   0   0   1   7   0   0 139   0   0]\n",
            " [  0   0   0   0   1   3   0   0 160   2]\n",
            " [  0   0   0   0   0   0   0   0   2 175]]\n"
          ]
        }
      ],
      "source": [
        "mlp_accuracy, mlp_precision, mlp_recall, mlp_cm = evaluate_tensorboard_model(mlp_model1, test_loader, mlp_writer, 0)\n",
        "\n",
        "cnn_accuracy, cnn_precision, cnn_recall, cnn_cm = evaluate_tensorboard_model(cnn_model2, test_loader, cnn_writer, 0)\n",
        "mlp_writer.close()\n",
        "cnn_writer.close()\n",
        "\n",
        "# TensorBoard Accuracy\n",
        "print(\"MLP:\")\n",
        "print(f\"Accuracy: {mlp_accuracy:.4f}\")\n",
        "print(f\"Precision: {mlp_precision:.4f}\")\n",
        "print(f\"Recall: {mlp_recall:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(mlp_cm)\n",
        "print()\n",
        "print(\"CNN :\")\n",
        "print(f\"Accuracy: {cnn_accuracy:.4f}\")\n",
        "print(f\"Precision: {cnn_precision:.4f}\")\n",
        "print(f\"Recall: {cnn_recall:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cnn_cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
